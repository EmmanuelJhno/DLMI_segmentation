{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raubyb/miniconda3/envs/MRIScoringEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/raubyb/miniconda3/envs/MRIScoringEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/raubyb/miniconda3/envs/MRIScoringEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/raubyb/miniconda3/envs/MRIScoringEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/raubyb/miniconda3/envs/MRIScoringEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/raubyb/miniconda3/envs/MRIScoringEnv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time \n",
    "import copy\n",
    "import argparse\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "\n",
    "import tqdm\n",
    "import pandas as pd \n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from models import get_model\n",
    "from data_loader.LiTS import LiTSDataset\n",
    "from utils.train import ObjFromDict\n",
    "\n",
    "\n",
    "def load_model(run_dir, metric='validation_dice'): \n",
    "    with open(os.path.join(run_dir,'config.json')) as json_file:\n",
    "        config = json.load(json_file)\n",
    "    config = ObjFromDict(config)\n",
    "    model = get_model(config.model)\n",
    "    checkpoint_path = os.path.join(run_dir, 'best_{}.pth'.format(metric)) \n",
    "    model.load_state_dict(torch.load(checkpoint_path, map_location='cpu'))\n",
    "    return model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_scale not specified in config, setting to default 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raubyb/LiTS/DLMI_segmentation/models/unet.py:85: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
      "/home/raubyb/LiTS/DLMI_segmentation/models/unet.py:89: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  nn.init.normal(m.weight.data, 1.0, 0.02)\n",
      "/home/raubyb/LiTS/DLMI_segmentation/models/unet.py:90: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  nn.init.constant(m.bias.data, 0.0)\n"
     ]
    }
   ],
   "source": [
    "run_dir = 'runs/2020-03-27_20h9min'\n",
    "model, config = load_model(run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_path  /home/raubyb/LiTS\n"
     ]
    }
   ],
   "source": [
    "data_path = config.dataset.root\n",
    "print('data_path ', data_path)\n",
    "\n",
    "# fix the seed for the split\n",
    "split_seed = 0 \n",
    "np.random.seed(split_seed)\n",
    "\n",
    "image_dir = os.listdir(os.path.join(data_path,'Training Batch 1')) + os.listdir(os.path.join(data_path,'Training Batch 2'))\n",
    "all_indexes = [ int(file_name[7:-4]) for file_name in image_dir if 'volume' in file_name]\n",
    "split = np.random.permutation(all_indexes)\n",
    "n_train, n_val, n_test = int(0.8 * len(split)), int(0.1 * len(split)), int(0.1 * len(split))\n",
    "\n",
    "train = split[: n_train]\n",
    "val = split[n_train : n_train+n_val]\n",
    "test = split[n_train + n_val :]\n",
    "\n",
    "\n",
    "# Setup Data Loader\n",
    "train_dataset = LiTSDataset(data_path, train, augment=True, no_tumor=True)\n",
    "val_dataset = LiTSDataset(data_path, val, no_tumor=True)\n",
    "test_dataset = LiTSDataset(data_path, test, no_tumor=True)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, num_workers=config.dataset.num_workers, batch_size=config.training.batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset, num_workers=config.dataset.num_workers, batch_size=config.training.batch_size, shuffle=False)\n",
    "test_dataloader  = DataLoader(dataset=test_dataset,  num_workers=config.dataset.num_workers, batch_size=config.training.batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "val_dataloader = DataLoader(dataset=val_dataset, num_workers=config.dataset.num_workers, batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in tqdm.tqdm(enumerate(val_dataloader)):\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = output[0,1,:,:,:]\n",
    "np.unique(volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRIScoringEnv",
   "language": "python",
   "name": "mriscoringenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
